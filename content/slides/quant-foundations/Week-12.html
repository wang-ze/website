<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>ESC_PS 8850:  Quantitative Foundations in Educational Research</title>
    <meta charset="utf-8" />
    <meta name="author" content="Ze Wang" />
    <meta name="date" content="2021-11-15" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis-fonts.css" rel="stylesheet" />
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="custom.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# ESC_PS 8850: <br>Quantitative Foundations in Educational Research
## <br/>Monday, 4:00pm-6:30pm; online
### Ze Wang
### University of Missouri
### 2021-11-15

---

layout: true

&lt;div class = 'my-header'&gt;&lt;span&gt;ESC_PS 8850 Quant Foundations&lt;/span&gt;&lt;/div&gt;

&lt;div class = 'my-footer'&gt;&lt;span&gt;wangze@missouri.edu
&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;
&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;&amp;emsp;
Ze Wang, Ph.D.&lt;/span&gt;&lt;/div&gt; 


---
class: center, middle








# .blue[Week 12]

## .blue[Analysis of Covariance (ANCOVA)]


---


```r
library(rio); library(ggplot2); library(QuantPsyc); library(psych); library(car); library(memisc); library(multcomp)
```

---

### ANCOVA

- One-way ANCOVA is used to describe the differences in predicted outcomes for a single dependent variable among multiple groups.  

- The design has one treatment factor that represents group membership, a continuous independent variable, and a continuous dependent measure.  

- ANCOVA analysis is used when the treatment and covariate do not interact.  In this case, ANCOVA allows us to increase the power of our analysis and adjust outcome means due to initial group differences on the covariate.  


---

### ANCOVA

**Example:** If we are conducting a study in which we are interested in treatment effects on an achievement variable and we see that IQ is positively correlated with achievement (r = .60). By squaring the correlation between IQ and achievement, we see that IQ accounts for 36% of the within group variance in achievement. We are only interested in the effects of treatment.  ANCOVA luckily removes the part of the variance due to IQ.  It controls for the effects of IQ.  

&lt;table class=" lightable-classic" style='font-family: "Arial Narrow", "Source Sans Pro", sans-serif; margin-left: auto; margin-right: auto;'&gt;
 &lt;thead&gt;
&lt;tr&gt;
&lt;th style="empty-cells: hide;" colspan="1"&gt;&lt;/th&gt;
&lt;th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2"&gt;&lt;div style="border-bottom: 1px solid #111111; margin-bottom: -1px; "&gt;Treatment 1&lt;/div&gt;&lt;/th&gt;
&lt;th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2"&gt;&lt;div style="border-bottom: 1px solid #111111; margin-bottom: -1px; "&gt;Treatment 2&lt;/div&gt;&lt;/th&gt;
&lt;/tr&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt;  &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; IQ &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Achievement &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; IQ &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; Achievement &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 100.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 23.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 96.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 19.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 113.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 31.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 108.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 26.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 98.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 35.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 122.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 31.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 110.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 28.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 103.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 22.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 124.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 40.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 132.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 36.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 135.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 42.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 120.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 38.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 118.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 37.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 111.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 31.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 93.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 29.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 93.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 25.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 120.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 34.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 115.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 29.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 127.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 45.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 125.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 41.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 115.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 33.0 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 102.00 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 27.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;border-bottom: 1px solid"&gt;  &lt;/td&gt;
   &lt;td style="text-align:right;border-bottom: 1px solid"&gt; 104.00 &lt;/td&gt;
   &lt;td style="text-align:right;border-bottom: 1px solid"&gt; 25.0 &lt;/td&gt;
   &lt;td style="text-align:right;border-bottom: 1px solid"&gt; 107.00 &lt;/td&gt;
   &lt;td style="text-align:right;border-bottom: 1px solid"&gt; 21.00 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Mean &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 113.08 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 33.5 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 111.17 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 28.83 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

---

### ANCOVA

Run a t-test comparing the two treatment groups. 


```r
dat &lt;- import("data/ancova_example.sav")
# head(dat)
t.test(dat$achieve ~ dat$treatment, var.equal = TRUE) # assume equal variance between groups
```

```
## 
## 	Two Sample t-test
## 
## data:  dat$achieve by dat$treatment
## t = 1.675, df = 22, p-value = 0.1081
## alternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0
## 95 percent confidence interval:
##  -1.111453 10.444786
## sample estimates:
## mean in group 1 mean in group 2 
##        33.50000        28.83333
```

```r
# t.test(dat$achieve ~ dat$treatment, var.equal = FALSE) # equal variance between groups not assumed. This is default.
# leveneTest(dat$achieve ~ as.factor(dat$treatment)) # test equality of variance between groups
```

---

### ANCOVA

**Example:** If we are conducting a study in which we are interested in treatment effects on an achievement variable and we see that IQ is positively correlated with achievement (r = .60). By squaring the correlation between IQ and achievement, we see that IQ accounts for 36% of the within group variance in achievement. We are only interested in the effects of treatment.  ANCOVA luckily removes the part of the variance due to IQ.  It controls for the effects of IQ. 

Run an ANOVA


```r
model.anova &lt;- aov(achieve ~ as.factor(treatment), data = dat)
summary(model.anova)
```

```
##                      Df Sum Sq Mean Sq F value Pr(&gt;F)
## as.factor(treatment)  1  130.7  130.67   2.805  0.108
## Residuals            22 1024.7   46.58
```


---

### ANCOVA

**Example:** If we are conducting a study in which we are interested in treatment effects on an achievement variable and we see that IQ is positively correlated with achievement (r = .60). By squaring the correlation between IQ and achievement, we see that IQ accounts for 36% of the within group variance in achievement. We are only interested in the effects of treatment.  ANCOVA luckily removes the part of the variance due to IQ.  It controls for the effects of IQ. 

Run an ANCOVA 


```r
*model.ancova &lt;- aov(achieve ~ IQ + as.factor(treatment), data = dat)
                  # type I Sums of Squares. Order of entry matters!
summary(model.ancova)
```

```
##                      Df Sum Sq Mean Sq F value  Pr(&gt;F)    
## IQ                    1  711.2   711.2   41.76 2.1e-06 ***
## as.factor(treatment)  1   86.5    86.5    5.08   0.035 *  
## Residuals            21  357.6    17.0                    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```


---

### ANCOVA

**Example:** If we are conducting a study in which we are interested in treatment effects on an achievement variable and we see that IQ is positively correlated with achievement (r = .60). By squaring the correlation between IQ and achievement, we see that IQ accounts for 36% of the within group variance in achievement. We are only interested in the effects of treatment.  ANCOVA luckily removes the part of the variance due to IQ.  It controls for the effects of IQ. 

**ANCOVA provides a more powerful test than ANOVA (and the t-test) for this example.**

*Other Examples:*
1.	Reduce bias when comparing intact  or self-selected groups (e.g., males vs. females)
2.	Adjust the posttest means on the dependent variable for any initial differences that may be present


---
#### Purposes of ANCOVA

- Elimination of systematic bias
  - Systematic bias:  Groups differ systematically on some variable that is related to the dependent variable.  Not sure if differences are due to treatment or group differences when beginning the study.
  
  - Random assignment takes care of systematic bias, but we are not always able to randomly assign participants to groups.  
  
  - You could match participants on certain variables.
  
  - ANCOVA can reduce this bias. 
  
---
#### Purposes of ANCOVA

-	Reduction of within group or error variance
  - What happens when we have smaller error variance? `\(M{S_b}/M{S_w}\)`

  To remove the variance due to the covariate:
  
    - The amount of variance on the dependent variable that is accounted for by the covariate is the squared value of the correlation between the two variables ( `\(r_{xy}^{2}\)`). The within group variance in ANCOVA has removed the portion due to the covariate:
    
`$$M{{S}_{w}}-M{{S}_{w}}r_{xy}^{2}=M{{S}_{w}}(1-r_{xy}^{2})$$` 

    - The new error term used in ANCOVA:
`\(MS_{w}^{*}=M{{S}_{w}}(1-r_{xy}^{2})[1+1/({{f}_{e}}-2)]\)`, where `\({f_e}\)` is the error degrees of freedom.


    - Example:  One-way ANOVA (3 groups with 20 participants per group).  The F = 200/100 = 2, which is not significant.  Participants were pretested, but the pretest was not used as a covariate and is correlated with the posttest at .71.  Using ANCOVA:  	`\(MS_{w}^{*}\approx 100[1-{{(.71)}^{2}}]=50\)`
So, for example:  `\({{F}^{*}}=190/50=3.8\)`, which is significant.

---
#### Choice of Covariates to Use

1.	Variables that should correlate with the dependent variable

2.	Variables that have been shown to correlate with similar types of participants

3.	Ideally, the covariates should correlate significantly with the dependent variable but low correlations with other covariates (if two covariates are highly correlated with each other (e.g., .80), they will be removing much of the same error variance from the dependent variable.

4.	Limit the number of covariates to satisfy the following relationship:
`\(\frac{[C+(J-1)]}{N}&lt;.10\)`, where C is the number of covariates, J is the number of treatment groups, and N is the total sample size.  In studies where the ratio is greater than .10, the adjusted means become unstable.  


---
#### Statistical Model for ANCOVA

`$$y_{ij} = \mu  + {\alpha _j} + \beta {z_{ij}} + {\varepsilon _{ij}}$$`
- `\(y_{ij}\)` is the *ith* score of the *jth* group. 
- `\(\mu\)` is the constant common to all *y* scores
- `\(\alpha_j\)` is teh effect of the *jth* treatment level (i.e, the group-specific effect)
- `\(\beta {z_{ij}}\)` quantifies the influence of the covariate (*z*) on the dependent variable (*y*). Note that the parameter `\(\beta\)` represents the degree of (linear) relation between the covariate and teh dependent variable.
- `\(\varepsilon _{ij}\)` reflects random variation due to any uncontrolled source.

**ANCOVA** combined features of ANOVA and linear regression. The group effects are specificed as in ANOVA, the relation between the covariate and the dependent variable is specified as in linear regression.

---
### ANCOVA Assumptions

#### Same three assumptions in ANOVA apply:

1.  Independence:  the residuals are independent in the population.
  - Consider study circumstances to identify any possible violations.

2.  Normality:  the residuals are normally distributed for each group in the population.
  - Inspect the distribution of the residuals for each group (use visual displays, descriptive and Shapiro-Wilk test to determine if residuals for each group are non-normally distributed).

3.  Homogeneity of Variance:  the variance of the residuals is the same for each group in the population.
  - Use Leveneâ€™s test to identify if the residual variation is the same across groups.


---
### ANCOVA Assumptions

#### ANCOVA-specific Assumptions

- **Linearity**:  The relationship between the covariate and the dependent variable is linear for each group in the population.
 - Inspect the scatterplot of the covariate and outcome within each group to determine that the relationship is reasonably linear.
 
- **Independence of the covariate and the independent variable**: The covariate shares its variance only with the DV that is not explained by the IV. 
  - Rarely the case in reality
  - If violated, the effect of the IV is confounded with the effect of the covariate.
  
- **Homogeneity of regression slopes**: The regression slope has the same value across all groups in the population. The regression lines of different groups should be parallel. 
	- No interaction effect between the covariate and the IV.
	- Test if the interaction term between the IV and the covariate is statistically significant.

 
---
### ANCOVA Assumptions

#### Homogeneity of regression slopes

.pull-left[
&lt;img src="images/ANCOVA_regression_slope_equal.png" width="749" /&gt;
Regression slope does not depend on the groups.
]


.pull-right[
&lt;img src="images/ANCOVA_regression_slope_non_equal.png" width="752" /&gt;
Regression slope varies with the groups.
]

---
#### ANCOVA Example

**Example**: Reading achievement and training conditions
- Dependent variable: Reading achievement (RA)
- Independent variable: Training condition (a = control, b = non-parental, c = parental)
- Covariate: Initial reading experience (IRE)


```r
reading &lt;- c(40,33,34,35,44,48,43,51,46,38,44,46,42,54,43)
groups &lt;- as.factor(rep(c("a", "b", "c"), each = 5))
init.read &lt;- c(37,23,30,35,41,45,40,44,45,30,40,41,37,51,39)
dat &lt;- data.frame(reading, groups, init.read)
```


---
#### ANCOVA Example

**Example**: Reading achievement and training conditions

```r
model.anova&lt;-aov(reading ~ groups, data = dat)
summary(model.anova)
```

```
##             Df Sum Sq Mean Sq F value Pr(&gt;F)  
## groups       2  230.5   115.3   4.968 0.0268 *
## Residuals   12  278.4    23.2                 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

```r
*model.ancova&lt;-aov(reading ~ init.read + groups, data = dat)
summary(model.ancova)
```

```
##             Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## init.read    1  443.6   443.6 101.222 6.96e-07 ***
## groups       2   17.1     8.6   1.956    0.188    
## Residuals   11   48.2     4.4                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

---
#### ANCOVA Example
##### Assumptions - Normality

```r
tapply(dat$reading, groups, shapiro.test) # Testing each grouop separately
```

```
## $a
## 
## 	Shapiro-Wilk normality test
## 
## data:  X[[i]]
## W = 0.88391, p-value = 0.3274
## 
## 
## $b
## 
## 	Shapiro-Wilk normality test
## 
## data:  X[[i]]
## W = 0.98143, p-value = 0.9421
## 
## 
## $c
## 
## 	Shapiro-Wilk normality test
## 
## data:  X[[i]]
## W = 0.81558, p-value = 0.1079
```

```r
#tapply(dat$init.read, groups, shapiro.test)
```


---
#### ANCOVA Example
##### Assumptions - Homogeneity of Variance

```r
#library(car)
leveneTest(reading ~ groups, data = dat)
```

```
## Levene's Test for Homogeneity of Variance (center = median)
##       Df F value Pr(&gt;F)
## group  2  0.0363 0.9645
##       12
```

---
#### ANCOVA Example
##### Assumptions - Independence of the covariate and the independent variable

This assumption can be tested using a regression model where the covariate is used as the outcome. Non-significant terms indicate independence.

```r
summary(lm(init.read ~ groups, data = dat))
```

```
## 
## Call:
## lm(formula = init.read ~ groups, data = dat)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
##  -10.8   -2.9   -0.6    4.0    9.4 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)   33.200      2.813  11.802 5.82e-08 ***
## groupsb        7.600      3.978   1.910   0.0803 .  
## groupsc        8.400      3.978   2.111   0.0564 .  
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 6.29 on 12 degrees of freedom
## Multiple R-squared:  0.3116,	Adjusted R-squared:  0.1969 
## F-statistic: 2.716 on 2 and 12 DF,  p-value: 0.1064
```

---
#### ANCOVA Example
##### Assumptions - Homogeneity of regression slopes

Homogeneity of regression slopes can be tested through including an interaction term in the ANCOVA model. A non-significant interaction term indicates equal regression slopes.


```r
model2 &lt;- aov(reading ~ init.read* groups, data = dat)
summary(model2)
```

```
##                  Df Sum Sq Mean Sq F value   Pr(&gt;F)    
## init.read         1  443.6   443.6  95.269 4.38e-06 ***
## groups            2   17.1     8.6   1.841    0.214    
## init.read:groups  2    6.3     3.2   0.677    0.532    
## Residuals         9   41.9     4.7                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

```r
Anova(model2, type = "III")
```

```
## Anova Table (Type III tests)
## 
## Response: reading
##                  Sum Sq Df F value   Pr(&gt;F)   
## (Intercept)      53.403  1 11.4693 0.008042 **
## init.read        65.995  1 14.1738 0.004452 **
## groups            3.636  2  0.3905 0.687664   
## init.read:groups  6.300  2  0.6766 0.532440   
## Residuals        41.905  9                    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

---
#### ANCOVA Example
##### Assumptions - Homogeneity of regression slopes



```r
ggplot(data=dat, aes(x=init.read, y=reading, group=groups, color=groups)) + 
  geom_point() + 
  geom_smooth(method = "lm", se = FALSE)
```

&lt;img src="Week-12_files/figure-html/unnamed-chunk-16-1.png" width="45%" /&gt;

---
#### Post-hoc Tests using the `multcomp` package


```r
# library(multcomp)
out &lt;- glht(model.ancova, linfct = mcp(groups = "Tukey"))
summary(out)
```

```
## 
## 	 Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: Tukey Contrasts
## 
## 
## Fit: aov(formula = reading ~ init.read + groups, data = dat)
## 
## Linear Hypotheses:
##            Estimate Std. Error t value Pr(&gt;|t|)
## b - a == 0  2.70817    1.51197   1.791    0.217
## c - a == 0  2.75114    1.55054   1.774    0.222
## c - b == 0  0.04297    1.32621   0.032    0.999
## (Adjusted p values reported -- single-step method)
```

---
#### Post-hoc Tests using the `multcomp` package

User-defined contrasts:


```r
K &lt;-rbind(c(1, -1/2, -1/2), # compares control versus mean of both treatment groups
c(0, -1, 1)) # compares means of treatment 1 and 2
rownames(K) &lt;-c("control vs ave.treatment", "treatment 2 vs treatment 1")
colnames(K) &lt;-c("Group A", "Group B", "Group C")
K
```

```
##                            Group A Group B Group C
## control vs ave.treatment         1    -0.5    -0.5
## treatment 2 vs treatment 1       0    -1.0     1.0
```

```r
out &lt;-glht(model.ancova, linfct= mcp(groups = K))
summary(out)
```

```
## 
## 	 Simultaneous Tests for General Linear Hypotheses
## 
## Multiple Comparisons of Means: User-defined Contrasts
## 
## 
## Fit: aov(formula = reading ~ init.read + groups, data = dat)
## 
## Linear Hypotheses:
##                                 Estimate Std. Error t value Pr(&gt;|t|)
## control vs ave.treatment == 0   -2.72965    1.38036  -1.977    0.138
## treatment 2 vs treatment 1 == 0  0.04297    1.32621   0.032    0.999
## (Adjusted p values reported -- single-step method)
```


---
### ANCOVA as a GLM

The ANCOVA model can be reformulated as as GLM using the following regression equation:

`$$y = {\beta _0} + \sum\limits_{j = 1}^{k - 1} {{\beta _j}{x_j} + {\beta _{yz}}z + \varepsilon }$$`

`\({\beta _0}\)` is the intercept; `\({\beta _j}\)` represents the *k*-1 slopes of the *k* groups; `\({\beta _{yz}}\)` is the slope of the covariate (*z*); `\(\varepsilon\)` is the error term.

Equation of the ANCOVA example, with group A as the reference group:

`$$y = {\beta _0} + {\beta _1}condB + {\beta _2}condC + {\beta _3}init.read + \varepsilon$$`

---
### ANCOVA as a GLM

Data matrix using dummy coding:

&lt;img src="images/ANCOVA_as_GLM_matrix_dummy.png" width="60%" /&gt;

---
### ANCOVA as a GLM

ANCOVA can be re-characterized as model selection problem:

**Step 1**: Estimate a base model that incorporates all covariates.

```r
m0 &lt;-lm(reading ~ init.read, data = dat)
```

**Step 2**: Add the independent variable of interest to the model.


```r
m1 &lt;-lm(reading ~ init.read + groups, data = dat)
```

**Step 3**: Check whether the independent variable contributes to predicting the outcome.


```r
anova(m0, m1)
```

```
## Analysis of Variance Table
## 
## Model 1: reading ~ init.read
## Model 2: reading ~ init.read + groups
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1     13 65.347                           
## 2     11 48.205  2    17.141 1.9557 0.1876
```

---
### ANCOVA as a GLM


```r
contrasts(dat$groups) &lt;- contr.treatment(n = 3, base = 1)
model3 &lt;-lm(reading ~ init.read + groups, data = dat)
contrasts(dat$groups)
```

```
##   2 3
## a 0 0
## b 1 0
## c 0 1
```


---
### ANCOVA as a GLM


```r
summary(model3)
```

```
## 
## Call:
## lm(formula = reading ~ init.read + groups, data = dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.4533 -0.9807 -0.1244  0.9933  3.5719 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 14.08307    3.32414   4.237   0.0014 ** 
## init.read    0.69629    0.09607   7.248 1.65e-05 ***
## groups2      2.70817    1.51197   1.791   0.1008    
## groups3      2.75114    1.55054   1.774   0.1037    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.093 on 11 degrees of freedom
## Multiple R-squared:  0.9053,	Adjusted R-squared:  0.8794 
## F-statistic: 35.04 on 3 and 11 DF,  p-value: 6.351e-06
```

---
### ANCOVA as a GLM


```r
anova(model3)
```

```
## Analysis of Variance Table
## 
## Response: reading
##           Df Sum Sq Mean Sq  F value    Pr(&gt;F)    
## init.read  1 443.59  443.59 101.2220 6.957e-07 ***
## groups     2  17.14    8.57   1.9557    0.1876    
## Residuals 11  48.21    4.38                       
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

---
### ANCOVA as a GLM


```r
contrasts(dat$groups) &lt;- contr.treatment(n = 3, base = 2)
model4 &lt;-lm(reading ~ init.read + groups, data = dat)
contrasts(dat$groups)
```

```
##   1 3
## a 1 0
## b 0 0
## c 0 1
```
---
### ANCOVA as a GLM


```r
summary(model4)
```

```
## 
## Call:
## lm(formula = reading ~ init.read + groups, data = dat)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.4533 -0.9807 -0.1244  0.9933  3.5719 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 16.79124    4.02999   4.167  0.00157 ** 
## init.read    0.69629    0.09607   7.248 1.65e-05 ***
## groups1     -2.70817    1.51197  -1.791  0.10079    
## groups3      0.04297    1.32621   0.032  0.97474    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 2.093 on 11 degrees of freedom
## Multiple R-squared:  0.9053,	Adjusted R-squared:  0.8794 
## F-statistic: 35.04 on 3 and 11 DF,  p-value: 6.351e-06
```

---
### ANCOVA as a GLM


```r
anova(model4)
```

```
## Analysis of Variance Table
## 
## Response: reading
##           Df Sum Sq Mean Sq  F value    Pr(&gt;F)    
## init.read  1 443.59  443.59 101.2220 6.957e-07 ***
## groups     2  17.14    8.57   1.9557    0.1876    
## Residuals 11  48.21    4.38                       
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
